# Practical Session #1: Introduction

1. Find in news sources a general public article reporting the discovery of a software bug. Describe the bug. If possible, say whether the bug is local or global and describe the failure that manifested its presence. Explain the repercussions of the bug for clients/consumers and the company or entity behind the faulty program. Speculate whether, in your opinion, testing the right scenario would have helped to discover the fault.

2. Apache Commons projects are known for the quality of their code and development practices. They use dedicated issue tracking systems to discuss and follow the evolution of bugs and new features. The following link https://issues.apache.org/jira/projects/COLLECTIONS/issues/COLLECTIONS-794?filter=doneissues points to the issues considered as solved for the Apache Commons Collections project. Among those issues find one that corresponds to a bug that has been solved. Classify the bug as local or global. Explain the bug and the solution. Did the contributors of the project add new tests to ensure that the bug is detected if it reappears in the future?

3. Netflix is famous, among other things we love, for the popularization of *Chaos Engineering*, a fault-tolerance verification technique. The company has implemented protocols to test their entire system in production by simulating faults such as a server shutdown. During these experiments they evaluate the system's capabilities of delivering content under different conditions. The technique was described in [a paper](https://arxiv.org/ftp/arxiv/papers/1702/1702.05843.pdf) published in 2016. Read the paper and briefly explain what are the concrete experiments they perform, what are the requirements for these experiments, what are the variables they observe and what are the main results they obtained. Is Netflix the only company performing these experiments? Speculate how these experiments could be carried in other organizations in terms of the kind of experiment that could be performed and the system variables to observe during the experiments.

4. [WebAssembly](https://webassembly.org/) has become the fourth official language supported by web browsers. The language was born from a joint effort of the major players in the Web. Its creators presented their design decisions and the formal specification in [a scientific paper](https://people.mpi-sws.org/~rossberg/papers/Haas,%20Rossberg,%20Schuff,%20Titzer,%20Gohman,%20Wagner,%20Zakai,%20Bastien,%20Holman%20-%20Bringing%20the%20Web%20up%20to%20Speed%20with%20WebAssembly.pdf) published in 2018. The goal of the language is to be a low level, safe and portable compilation target for the Web and other embedding environments. The authors say that it is the first industrial strength language designed with formal semantics from the start. This evidences the feasibility of constructive approaches in this area. Read the paper and explain what are the main advantages of having a formal specification for WebAssembly. In your opinion, does this mean that WebAssembly implementations should not be tested? 

5.  Shortly after the appearance of WebAssembly another paper proposed a mechanized specification of the language using Isabelle. The paper can be consulted here: https://www.cl.cam.ac.uk/~caw77/papers/mechanising-and-verifying-the-webassembly-specification.pdf. This mechanized specification complements the first formalization attempt from the paper. According to the author of this second paper, what are the main advantages of the mechanized specification? Did it help improving the original formal specification of the language? What other artifacts were derived from this mechanized specification? How did the author verify the specification? Does this new specification removes the need for testing?

## Answers

1. Lien de l'article : https://www.bleepingcomputer.com/news/security/ivanti-fixes-maximum-severity-rce-bug-in-endpoint-management-software/<br>
Ivanti a trouvé un bug important permettant à des personnes non authentifiées d'exécuter du code sur le cœur du serveur. C'est un risque global pour les entreprises utilisant le logiciel concerné, cependant personne ne l'a exploité à en croire l'article.
Le bug aurait été trouvé suite à une analyse poussée du code afin de déceler de potentiels bugs. Des tests plus approfondis lors du développement auraient permis de trouver ce bug.
2. Lien : https://issues.apache.org/jira/projects/COLLECTIONS/issues/COLLECTIONS-796?filter=doneissues <br>
Ce bug a été corrigé, et des tests ont été ajoutés afin de s'assurer de ne pas le recréer. C'est un bug local qui n'impacte que la méthode SetUniqueList.createSetBasedOnList qui n'ajoutait pas les éléments dans la valeur de retour. Cela est dû à une erreur de suppression de code, le morceau de code manquant a donc été remis.

3. Pour faire des tests de type *Chaos Engineering* Netflix va d'abord s'accorder sur un état stable avec élements mesurables où tout fonctionne bien à priori. Puis, ils vont simuler un problème pouvant arriver en production comme un crash de serveur afin de voir comment le système réagit. Ils vont donc créer un groupe de contrôle qui continue de tourner normalement et un groupe test qui subira le *crash*. Ils vont ensuite s'assurer que malgré le crash le système ne sera pas impacté à la fin et que le groupe de test sera semblable au groupe de contrôle. Ils peuvent par exemple vérifier que malgré le problème, les clients peuvent toujours accéder au contenu. D'autres entreprises doivent avoir recours à ce genre de type de tests, mais ils ne vont pas chercher à observer les mêmes choses. Par exemple une entreprise comme Google pourrait faire ce genre de test et mesurer le temps de latence que met le site à répondre en cas de panne.
4. Avoir une spécification formelle sur WebAssembly permet de s'assurer que ce qui est développé suit des contraintes avancées et fiables. Cela rend le code plus sûr car on fixe un cadre, cela le rend clair car on sait dans quelle direction on va et on est sûr de ne pas en sortir. Ceci dit, cette spécification formelle ne remplace pas les tests, elle permet de s'assurer d'aller dans le bon sens et de suivre le cadre que l'on s'est fixé, cependant elle ne permet de pas tester les fonctionnalités que l'on développe ou qu'il n'y a pas de bugs.
5. Cette spécification mécanique a pu permettre de trouver des bugs au sein de la spécification originelle. Aussi, cela a permis de mettre en place un vérifieur de type pour être sûr de ce que l'on implémente en WebAssembly ainsi qu'un interpréteur. De plus, cela permet aussi une *proximité visuelle* dans les règles de réduction et de typage. Cette nouvelle spécification ne permet toujours pas de se passer de tests, pour les mêmes raisons évoquées au-dessus. 