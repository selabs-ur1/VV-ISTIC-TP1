# Practical Session #1: Introduction

1. Find in news sources a general public article reporting the discovery of a software bug. Describe the bug. If possible, say whether the bug is local or global and describe the failure that manifested its presence. Explain the repercussions of the bug for clients/consumers and the company or entity behind the faulty program. Speculate whether, in your opinion, testing the right scenario would have helped to discover the fault.

2. Apache Commons projects are known for the quality of their code and development practices. They use dedicated issue tracking systems to discuss and follow the evolution of bugs and new features. The following link https://issues.apache.org/jira/projects/COLLECTIONS/issues/COLLECTIONS-794?filter=doneissues points to the issues considered as solved for the Apache Commons Collections project. Among those issues find one that corresponds to a bug that has been solved. Classify the bug as local or global. Explain the bug and the solution. Did the contributors of the project add new tests to ensure that the bug is detected if it reappears in the future?

3. Netflix is famous, among other things we love, for the popularization of *Chaos Engineering*, a fault-tolerance verification technique. The company has implemented protocols to test their entire system in production by simulating faults such as a server shutdown. During these experiments they evaluate the system's capabilities of delivering content under different conditions. The technique was described in [a paper](https://arxiv.org/ftp/arxiv/papers/1702/1702.05843.pdf) published in 2016. Read the paper and briefly explain what are the concrete experiments they perform, what are the requirements for these experiments, what are the variables they observe and what are the main results they obtained. Is Netflix the only company performing these experiments? Speculate how these experiments could be carried in other organizations in terms of the kind of experiment that could be performed and the system variables to observe during the experiments.

4. [WebAssembly](https://webassembly.org/) has become the fourth official language supported by web browsers. The language was born from a joint effort of the major players in the Web. Its creators presented their design decisions and the formal specification in [a scientific paper](https://people.mpi-sws.org/~rossberg/papers/Haas,%20Rossberg,%20Schuff,%20Titzer,%20Gohman,%20Wagner,%20Zakai,%20Bastien,%20Holman%20-%20Bringing%20the%20Web%20up%20to%20Speed%20with%20WebAssembly.pdf) published in 2018. The goal of the language is to be a low level, safe and portable compilation target for the Web and other embedding environments. The authors say that it is the first industrial strength language designed with formal semantics from the start. This evidences the feasibility of constructive approaches in this area. Read the paper and explain what are the main advantages of having a formal specification for WebAssembly. In your opinion, does this mean that WebAssembly implementations should not be tested? 

5.  Shortly after the appearance of WebAssembly another paper proposed a mechanized specification of the language using Isabelle. The paper can be consulted here: https://www.cl.cam.ac.uk/~caw77/papers/mechanising-and-verifying-the-webassembly-specification.pdf. This mechanized specification complements the first formalization attempt from the paper. According to the author of this second paper, what are the main advantages of the mechanized specification? Did it help improving the original formal specification of the language? What other artifacts were derived from this mechanized specification? How did the author verify the specification? Does this new specification removes the need for testing?

## Answers

1.
[source](https://www.bleepingcomputer.com/news/software/citrix-sophos-software-impacted-by-2024-leap-year-bugs/)

The Citrix leap year bug on February 29, 2024, caused their video redirection service on all virtual delivery agent machines to fail after restarts, disrupting video streaming in virtual desktop environments. Users had to perform manual workarounds like resetting system dates, which was impractical for large-scale setups. Proper testing could have indeed prevented the disruption as leap year is a common thing to take into account when working with a date system. It was a global bug. It has impacted both users’ productivity and Citrix’s reputation​.

2.
[Bug](https://issues.apache.org/jira/projects/COLLECTIONS/issues/COLLECTIONS-709?filter=doneissues&orderby=cf%5B10010%5D+ASC%2C+cf%5B12310200%5D+ASC%2C+updated+DESC)

Removing the final element(s) in a MultiSet doesn't set the count on a MultiSet.Entry to zero despite it not having elements anymore.to fix this, the one issuing the request proposed doing a special case for when the remove method of MultiSet is called to be able to handle the removal of the last element. they also added a proper test in the appropriate class. It is a local bug because it only affected a specific case of when remove was called, remove still worked as intended with other entry.getCount() values.

3.
Netflix's Chaos Engineering involves testing their systems in production by simulating failures, like failing requests between services or terminate virtual machine instances, to ensure reliability. They monitor variables like system uptime, latency, and error rates. The technique helps identify weaknesses and improve system resilience. Other companies like Amazon,Facebook,Microsoft and even Google also use similar approaches. Other organizations could focus on testing databases or authentication systems with that system, observing variables like response time and service availability.

4.
A formal specification defines the behavior of the language and its runtime environment precisely. A user with the full knowledge of the specification should know exactly how a piece of code would behave if executed. A formal specification also offers the user a full knowledge of certain elements that you wouldn't of normally like memory management or exception handling for example. It also facilitate the creation of tests. Even with a formal specification WebAssembly absolutely still needs to be tested, there is no reason it shouldn't, in fact formal specification encourages it.

5.
In tandem with the formal specification, the mechanized specification offers precision and an automated verification that can produce a fully mechanised proof of properties which hasn't been done before this. Mechanized specification helped refine the original formal specification by identifying inconsistencies in it. Artifacts derived from this mechanized specification include proofs of properties and verification conditions for the language's implementation. The author verified the specification by formal proofs within Isabelle. This doesn't mean that we shouldn't test anymore, there is always the possibility of missing something, also Isabelle doesn't help us to test issues like performance or cross-platform behavior.
 

